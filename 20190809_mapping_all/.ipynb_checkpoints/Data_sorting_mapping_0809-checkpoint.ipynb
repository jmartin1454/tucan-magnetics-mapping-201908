{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this notebook produces data file swhich are read by the other evaluation notebooks. The height offset between RUN1-3 and RUN4 are corrected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib notebook \n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read raw csv data, the files with name \"_corr\" are the ones after manually correcting typos during measurements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format of csv files:\n",
    "#  0: cycle number\n",
    "#  1: UNIX time stamped at the end of the first of the five measurements \n",
    "#  2: UNIX time stamped at the end of the last of the five measurements \n",
    "#  3: u (in cm)\n",
    "#  4: v (in cm)\n",
    "#  5: w (in cm)\n",
    "#  6: B_u (G), average of the five measurements\n",
    "#  7: B_v (G)\n",
    "#  8: B_w (G)\n",
    "#  9: dB_u (G), standard deviation evaluated from the five measurements\n",
    "#  10: dB_v (G)\n",
    "#  11: dB_w (G)\n",
    "\n",
    "df_names = ['cycle','time_start','time_end','u','v0','w', 'B_u','dB_u','B_v','dB_v','B_w','dB_w']\n",
    "df1 = pd.read_csv('Mapping_0809_all/20190809_1623_run1_avg.csv', names=df_names)\n",
    "df2 = pd.read_csv('Mapping_0809_all/20190809_1650_run2_avg_corr.csv', names=df_names)\n",
    "df3 = pd.read_csv('Mapping_0809_all/20190809_1800_run3_1_avg.csv', names=df_names)\n",
    "df4 = pd.read_csv('Mapping_0809_all/20190809_1936_run4_avg_corr.csv', names=df_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN1-3 uses floor as  v=0, RUN4 uses the platform as v=0, this is corrected so that the platform is v=0 for all the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['v'] = df1['v0']-188.12\n",
    "df2['v'] = df2['v0']-188.12\n",
    "df3['v'] = df3['v0']-188.12\n",
    "df4['v'] = df4['v0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('Mapping_0809_RUN1.csv', columns=['cycle','time_start','time_end','u','v','w', 'B_u','dB_u','B_v','dB_v','B_w','dB_w'],\n",
    "           index=False)\n",
    "df2.to_csv('Mapping_0809_RUN2.csv', columns=['cycle','time_start','time_end','u','v','w', 'B_u','dB_u','B_v','dB_v','B_w','dB_w'],\n",
    "           index=False)\n",
    "df3.to_csv('Mapping_0809_RUN3.csv', columns=['cycle','time_start','time_end','u','v','w', 'B_u','dB_u','B_v','dB_v','B_w','dB_w'],\n",
    "           index=False)\n",
    "df4.to_csv('Mapping_0809_RUN4.csv', columns=['cycle','time_start','time_end','u','v','w', 'B_u','dB_u','B_v','dB_v','B_w','dB_w'],\n",
    "           index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.870000000000005\n",
      "13.870000000000005\n",
      "-46.129999999999995\n",
      "202.37\n"
     ]
    }
   ],
   "source": [
    "print np.max(df1.v)\n",
    "print np.max(df2.v)\n",
    "print np.max(df3.v)\n",
    "print np.max(df4.v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
